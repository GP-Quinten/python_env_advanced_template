{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6e416ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to /home/gpinon/more_europa/clean_rdc_experiments/projects/P04_official_reg_db_creation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "working_dir = \"/home/gpinon/more_europa/clean_rdc_experiments/projects/P04_official_reg_db_creation\"\n",
    "os.chdir(working_dir)\n",
    "print(f\"Changed working directory to {working_dir}\")\n",
    "import logging\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pycountry\n",
    "\n",
    "from src.p04_official_reg_db_creation import config\n",
    "import llm_backends\n",
    "from llm_backends.cache import DiskCacheStorage\n",
    "from llm_backends.mistral import dummy_config\n",
    "from llm_backends.openai import dummy_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e6dc521",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD = \"geographical_area\"\n",
    "MODEL = \"small_mistral\"\n",
    "\n",
    "# Load environment variables from .env file and get API key\n",
    "load_dotenv()\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e82ddc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "registry_dataset = f\"../../datasets/006_registry_names_datasets/dedup_100_famous_european_registries.json\"\n",
    "publis_dataset_template = f\"../../datasets/006_registry_names_datasets/famous_european_registries_sample_publi_data/1.json\"\n",
    "prompt_txt = prompt_txt=f\"etc/prompts/extraction/prompt_{FIELD}.txt\"\n",
    "model_config=f\"etc/configs/{MODEL}_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb566499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUTS\n",
    "output_json = f\"data/W01/R01_extraction/{MODEL}/{FIELD}/{FIELD}_extractions.json\"\n",
    "output_records_jsonl = f\"data/W01/R01_extraction/{MODEL}/{FIELD}/{FIELD}_extractions_records.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1a1c0f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: mistral-small-latest\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directory exists\n",
    "out_dir = Path(output_json).parent\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure output records directory exists\n",
    "records_dir = Path(output_records_jsonl).parent\n",
    "records_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load model configuration\n",
    "with open(model_config, \"r\", encoding=\"utf-8\") as f:\n",
    "    model_cfg = json.load(f)\n",
    "\n",
    "model_name = model_cfg.get(\"model\", \"unknown\")\n",
    "print(f\"Using model: {model_name}\")\n",
    "\n",
    "# Load the annotation prompt\n",
    "with open(prompt_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt_template = f.read().strip()\n",
    "\n",
    "# Load registry_dataset\n",
    "with open(registry_dataset, \"r\") as file:\n",
    "    registry_dataset = json.load(file)\n",
    "\n",
    "# Load the publications dataset\n",
    "# first get input directory from template\n",
    "input_dir = Path(publis_dataset_template).parent\n",
    "# Get all input batch files and sort them by batch number\n",
    "batch_files = sorted(input_dir.glob(\"*.json\"), key=lambda p: int(p.stem))\n",
    "publis_dataset = []\n",
    "# Load each batch file\n",
    "for batch_file in batch_files:\n",
    "    with open(batch_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        batch_data = json.load(f)\n",
    "        publis_dataset.extend(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "279f5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select a small subset of the registry_dataset (first 5 elements)\n",
    "# registry_dataset = registry_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96c44395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registry Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registry_name</th>\n",
       "      <th>number_of_occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get With The Guidelines-Resuscitation</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swedish National Inpatient Register</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>National Registry for Radiation Workers</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>National Pathology Registry</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swedish Registry for Cognitive/Dementia Disorders</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       registry_name  number_of_occurrences\n",
       "0              Get With The Guidelines-Resuscitation                     86\n",
       "1                Swedish National Inpatient Register                     53\n",
       "2            National Registry for Radiation Workers                     19\n",
       "3                        National Pathology Registry                     11\n",
       "4  Swedish Registry for Cognitive/Dementia Disorders                     12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display 'registry_name' and 'number_of_occurrences' for each registry, in a pandas dataframe with display()\n",
    "df = pd.DataFrame(registry_dataset)\n",
    "print(\"Registry Dataset:\")\n",
    "display(df[[\"registry_name\", \"number_of_occurrences\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7f7619f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 3753 prompts for LLM processing.\n"
     ]
    }
   ],
   "source": [
    "# Prepare prompts for LLMs\n",
    "prompts_items = []\n",
    "total_prompts = 0\n",
    "for registry in registry_dataset:\n",
    "    registry_id = registry.get(\"object_id\", None)\n",
    "    # get \"list_publi_ids\" from registry\n",
    "    list_publi_ids = registry.get(\"list_publi_ids\", [])\n",
    "    for publi_id in list_publi_ids:\n",
    "        # find publication in publis_dataset\n",
    "        publication = next(\n",
    "            (pub for pub in publis_dataset if pub[\"object_id\"] == publi_id), None\n",
    "        )\n",
    "        if publication:\n",
    "            title = publication.get(\"title\", \"<no title>\")\n",
    "            abstract = publication.get(\"abstract\", \"<no abstract>\")\n",
    "            # Prepare the prompt for the LLM. replace registry_name_to_add and registry_acronym_to_add with needed values, then\n",
    "            prompt = prompt_template.replace(\n",
    "                \"{{registry_name_to_add}}\", registry[\"registry_name\"]\n",
    "            ).replace(\"{{registry_acronym_to_add}}\", registry[\"acronym\"])\n",
    "            prompt = f\"{prompt}\\nTitle: {title}\\nAbstract: {abstract}\"\n",
    "            prompts_items.append(\n",
    "                {\n",
    "                    \"prompt\": prompt,\n",
    "                    \"custom_id\": f\"{registry_id}_{publi_id}\",\n",
    "                    \"registry_id\": registry_id,\n",
    "                    \"publi_id\": publi_id,\n",
    "                }\n",
    "            )\n",
    "            total_prompts += 1\n",
    "            \n",
    "# print the number of prompts prepared\n",
    "print(f\"Prepared {total_prompts} prompts for LLM processing.\")\n",
    "\n",
    "# Create a list to store the records with object_id, prompt, and raw response\n",
    "prompt_response_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7bc7daf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First prompt item: {'prompt': 'Context:\\nPatient registries are structured, systematic databases that collect standardized, longitudinal, patient-level clinical data on populations defined by diseases, conditions, exposures, or treatments. They support observational research, epidemiological monitoring, clinical-outcomes evaluation, trend analyses, data-quality assessments, comparative studies, and linkage with other data sources. Administrative registries (e.g., hospital discharge, national cancer, stroke, chronic disease surveillance systems) qualify if they systematically collect patient-level data suitable for clinical or epidemiological analysis. Simple vital-statistics databases (birth/death) do NOT qualify.\\n\\nSituation:\\nThe publication that is given (title and abstract concatenated as Text_to_analyze) is registry related (it was manually checked), meaning that:\\n- a least one patient registry is mentioned in the text\\n- the publication/study uses or analyzes data from that registry\\n\\nTask:\\nGiven the publication’s title and abstract (as Text_to_analyze) and the given registry name that is used in the study (previously manually extracted), extract as accurately as possible the geographical area of the registry used in the study, or the geographical area of the patients from which data is collected (or list of geographical areas separated by commas) by following the exact JSON output format.\\n\\nAdditional instructions:\\n- The geographical area is often mentioned in the registry name. \\n    * Example: \"The French Registry of Patients with Aortic Stenosis\" --> Extract \\'France\\' as Geographical area.\\n- Use your personal knowledge when appropriate and when you are sure of the answer. Especially, you may identify the geographical area based on the name of the registry or the institution that runs it.\\n    * Example: \"Bedside Estimation of Risk From Percutaneous Coronary Interventions: The New Mayo Clinic Risk Scores\" --> Extract \\'USA\\' as Geographical area because Mayo Clinic is a famous US organization \\n- Determine the most precise location using the hierarchy below (if option 1 is not available, use option 2, etc.):\\n    1. City (+ Country)\\n        * Example: \"Paris, France\"\\n    2. Region or State (+ Country)\\n        * Example: \"California, United States of America\"\\n    3. Country\\n        * Example: \"USA\"\\n    4. Multinational / Union of Countries (fewer than 5) (+ List of countries if less than 5)\\n        * Example: \"Multinational - Scandinavia (Denmark, Norway, Sweden)\"\\n    5. International (More than 5 countries) (+ number of countries if available)\\n        * Example: \"International - Europe\"\\n    6. Worldwide (multiple continents)\\n        * Example: \"Worldwide (5 continents)\"\\n    --> If there is no information towards any of these 6 types of geographical area extractions, assign \\'Not found\\'.\\n- Output \\'United States of America\\' when the country used is the USA.\\n\\nSteps to follow in order:\\n1. Analyse the given Registry name. Most of the time the geographical area is mentioned in the registry name, but if not, you can use your personal knowledge to identify the geographical area of the registry or the patients from which data is collected.\\n   - If the registry name is not available, use the title and abstract of the publication to extract the geographical area of the registry or the patients from which data is collected.\\n   - If you cannot find any geographical area, assign \\'Not found\\'.\\n2. Extract the geographical area, using the given registry name, title and abstract.\\n3. Output\\n    - Strict JSON, no extra text:\\n        {\\n            \"registry_name\": \"<name>\",\\n            \"acronym\": \"<n>\",\\n            \"geographical_area\": \"<geographical area>\"\\n        }  \\n\\nFINAL NOTES:\\nOutput only the JSON. Do not add explanations.\\nDo not output more than 10 countries in the list of countries, as it would get too long. Please use \\'Multinational\\' or \\'Worldwide\\' or regions of the world such as \\'South America\\' or \\'Middle Eaast\\' or \\'Europe\\' instead.\\n\\n\\nINPUT:\\n\\nRegistry to analyze:\\n- Registry Name: \"Get With The Guidelines-Resuscitation\"\\n- Acronym: \"GWTG-R\"\\n\\nText_to_analyze:\\nTitle: Duration of cardiopulmonary resuscitation and outcomes for adults with in-hospital cardiac arrest: retrospective cohort study.\\nAbstract: To quantify time dependent probabilities of outcomes in patients after in-hospital cardiac arrest as a function of duration of cardiopulmonary resuscitation, defined as the interval between start of chest compression and the first return of spontaneous circulation or termination of resuscitation. Retrospective cohort study. Multicenter prospective in-hospital cardiac arrest registry in the United States. 348\\u2009996 adult patients (≥18 years) with an index in-hospital cardiac arrest who received cardiopulmonary resuscitation from 2000 through 2021. Survival to hospital discharge and favorable functional outcome at hospital discharge, defined as a cerebral performance category score of 1 (good cerebral performance) or 2 (moderate cerebral disability). Time dependent probabilities of subsequently surviving to hospital discharge or having favorable functional outcome if patients pending the first return of spontaneous circulation at each minute received further cardiopulmonary resuscitation beyond the time point were estimated, assuming that all decisions on termination of resuscitation were accurate (that is, all patients with termination of resuscitation would have invariably failed to survive if cardiopulmonary resuscitation had continued for a longer period of time). Among 348\\u2009996 included patients, 233\\u2009551 (66.9%) achieved return of spontaneous circulation with a median interval of 7 (interquartile range 3-13) minutes between start of chest compressions and first return of spontaneous circulation, whereas 115\\u2009445 (33.1%) patients did not achieve return of spontaneous circulation with a median interval of 20 (14-30) minutes between start of chest compressions and termination of resuscitation. 78\\u2009799 (22.6%) patients survived to hospital discharge. The time dependent probabilities of survival and favorable functional outcome among patients pending return of spontaneous circulation at one minute\\'s duration of cardiopulmonary resuscitation were 22.0% (75\\u2009645/343\\u2009866) and 15.1% (49\\u2009769/328\\u2009771), respectively. The probabilities decreased over time and were <1% for survival at 39 minutes and <1% for favorable functional outcome at 32 minutes\\' duration of cardiopulmonary resuscitation. This analysis of a large multicenter registry of in-hospital cardiac arrest quantified the time dependent probabilities of patients\\' outcomes in each minute of duration of cardiopulmonary resuscitation. The findings provide resuscitation teams, patients, and their surrogates with insights into the likelihood of favorable outcomes if patients pending the first return of spontaneous circulation continue to receive further cardiopulmonary resuscitation.', 'custom_id': '820_2cddbb8b-6805-5800-8b92-9455d3bae85b', 'registry_id': 820, 'publi_id': '2cddbb8b-6805-5800-8b92-9455d3bae85b'}\n"
     ]
    }
   ],
   "source": [
    "# show fisrt item of prompts_items\n",
    "print(f\"First prompt item: {prompts_items[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "557259ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prompts_list = []\n",
    "batch_size = 500\n",
    "for i in range(0, len(prompts_items), batch_size):\n",
    "    batch_prompts_list.append(prompts_items[i:i + batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "488f55fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch inference with mistral-small-latest...\n",
      "2025-07-22 15:26:04,569 - llm_backends.cache.disk.DiskCacheStorage - INFO - Disk cache initialized at: /home/gpinon/more_europa/clean_rdc_experiments/src/llm_backends/llm_backends/.cache\n",
      "Starting batch inference with mistral-small-latest...\n",
      "2025-07-22 15:26:04,682 - llm_backends.cache.disk.DiskCacheStorage - INFO - Disk cache initialized at: /home/gpinon/more_europa/clean_rdc_experiments/src/llm_backends/llm_backends/.cache\n",
      "Starting batch inference with mistral-small-latest...\n",
      "2025-07-22 15:26:04,784 - llm_backends.cache.disk.DiskCacheStorage - INFO - Disk cache initialized at: /home/gpinon/more_europa/clean_rdc_experiments/src/llm_backends/llm_backends/.cache\n",
      "Starting batch inference with mistral-small-latest...\n",
      "2025-07-22 15:26:04,892 - llm_backends.cache.disk.DiskCacheStorage - INFO - Disk cache initialized at: /home/gpinon/more_europa/clean_rdc_experiments/src/llm_backends/llm_backends/.cache\n",
      "Starting batch inference with mistral-small-latest...\n",
      "2025-07-22 15:26:05,048 - llm_backends.cache.disk.DiskCacheStorage - INFO - Disk cache initialized at: /home/gpinon/more_europa/clean_rdc_experiments/src/llm_backends/llm_backends/.cache\n",
      "Starting batch inference with mistral-small-latest...\n",
      "2025-07-22 15:26:05,176 - llm_backends.cache.disk.DiskCacheStorage - INFO - Disk cache initialized at: /home/gpinon/more_europa/clean_rdc_experiments/src/llm_backends/llm_backends/.cache\n",
      "Starting batch inference with mistral-small-latest...\n",
      "2025-07-22 15:26:05,272 - llm_backends.cache.disk.DiskCacheStorage - INFO - Disk cache initialized at: /home/gpinon/more_europa/clean_rdc_experiments/src/llm_backends/llm_backends/.cache\n",
      "Starting batch inference with mistral-small-latest...\n",
      "2025-07-22 15:26:05,369 - llm_backends.cache.disk.DiskCacheStorage - INFO - Disk cache initialized at: /home/gpinon/more_europa/clean_rdc_experiments/src/llm_backends/llm_backends/.cache\n"
     ]
    }
   ],
   "source": [
    "batch_raw_responses_list = []\n",
    "for batch_prompts in batch_prompts_list:\n",
    "    # Run batch inference based on model type\n",
    "    print(f\"Starting batch inference with {model_name}...\")\n",
    "\n",
    "    is_openai_model = \"openai\" in model_config.lower()\n",
    "    # if \"istral\" in the name of llm_judge_model_config, then we are using Mistral model\n",
    "    is_mistral_model = \"istral\" in model_config.lower()\n",
    "    if is_mistral_model:\n",
    "        backend = llm_backends.MistralBatchBackend(\n",
    "            api_key=os.getenv(\"MISTRAL_API_KEY\"), cache_storage=DiskCacheStorage()\n",
    "        )\n",
    "    elif is_openai_model:\n",
    "        backend = llm_backends.OpenAIAsyncBackend(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"), cache_storage=DiskCacheStorage()\n",
    "        )\n",
    "\n",
    "    batch_raw_responses = backend.infer_many(\n",
    "        prompt_items=batch_prompts,\n",
    "        model_config=model_cfg,\n",
    "    )\n",
    "    batch_raw_responses_list.append(batch_raw_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eb51f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.WARNING,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d111caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_number = 1\n",
    "# batch_llm_responses_list = []\n",
    "# initial_time = time.time()\n",
    "# for batch_raw_responses in batch_raw_responses_list:\n",
    "#     start_time = time.time()\n",
    "#     llm_responses = []\n",
    "#     for raw_response in batch_raw_responses:\n",
    "#         # Store the raw response with object_id and prompt for the records file\n",
    "#         prompt_obj = next(\n",
    "#             (p for p in prompts_items if p[\"custom_id\"] == raw_response[\"custom_id\"]), None\n",
    "#         )\n",
    "#         if prompt_obj:\n",
    "#             prompt_response_records.append(\n",
    "#                 {\n",
    "#                     \"custom_id\": raw_response[\"custom_id\"],\n",
    "#                     \"registry_id\": prompt_obj[\"registry_id\"],\n",
    "#                     \"publi_id\": prompt_obj[\"publi_id\"],\n",
    "#                     \"prompt\": prompt_obj[\"prompt\"],\n",
    "#                     \"llm_response\": raw_response,\n",
    "#                 }\n",
    "#             )\n",
    "#             # parse raw response\n",
    "#             parsed_response = backend._parse_response(raw_response)\n",
    "#             parsed_response[\"custom_id\"] = raw_response.get(\"custom_id\", \"\")\n",
    "#             parsed_response[\"registry_id\"] = prompt_obj[\"registry_id\"]\n",
    "#             parsed_response[\"publi_id\"] = prompt_obj[\"publi_id\"]\n",
    "#             # print(response)\n",
    "#             llm_responses.append(parsed_response)\n",
    "\n",
    "#     # print batch_number\n",
    "#     print(f\" --- Batch N°{batch_number} --- \")\n",
    "#     print(f\"Batch inference completed with {len(llm_responses)} responses\")\n",
    "#     elapsed_total = (time.time() - start_time)/ 60  # Convert to minutes\n",
    "#     print(f\"Total time for inference : {elapsed_total:.1f} minutes\")\n",
    "#     print(\"\")\n",
    "#     batch_number += 1\n",
    "#     batch_llm_responses_list.append(llm_responses)\n",
    "\n",
    "# total_computation_time = (time.time() - initial_time) / 60  # Convert to minutes\n",
    "# print(f\"--> Total computation time for all batches: {total_computation_time:.1f} minutes <--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "047e2bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Batch N°1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:26:05,538 - llm_backends.cache.disk.DiskCacheStorage - INFO - Attempting to retrieve cache for key: 0007ea35d5d5915399b3cb0e0a05c1ac078cf4767cec6522b7dba0ee3e04e0ea\n",
      "2025-07-22 15:26:05,542 - llm_backends.cache.disk.DiskCacheStorage - INFO - Cache hit for key: 0007ea35d5d5915399b3cb0e0a05c1ac078cf4767cec6522b7dba0ee3e04e0ea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference completed with 500 responses\n",
      "Total time for inference : 0.0 minutes\n",
      "\n",
      "--- Processing Batch N°2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:26:05,665 - llm_backends.cache.disk.DiskCacheStorage - INFO - Attempting to retrieve cache for key: e8c496285d4354ddb3b5c5a0b9d05edacf6b8e97c13d5788232491e1ba2a7d8e\n",
      "2025-07-22 15:26:05,669 - llm_backends.cache.disk.DiskCacheStorage - INFO - Cache hit for key: e8c496285d4354ddb3b5c5a0b9d05edacf6b8e97c13d5788232491e1ba2a7d8e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▌       | 2/8 [00:00<00:00, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference completed with 500 responses\n",
      "Total time for inference : 0.0 minutes\n",
      "\n",
      "--- Processing Batch N°3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:26:05,704 - llm_backends.cache.disk.DiskCacheStorage - INFO - Attempting to retrieve cache for key: 7ea24822fa1e01e1413e045c7d467a7afd77dcf6f65b8164a2b37c0762df819b\n",
      "2025-07-22 15:26:05,708 - llm_backends.cache.disk.DiskCacheStorage - INFO - Cache hit for key: 7ea24822fa1e01e1413e045c7d467a7afd77dcf6f65b8164a2b37c0762df819b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference completed with 500 responses\n",
      "Total time for inference : 0.0 minutes\n",
      "\n",
      "--- Processing Batch N°4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:26:05,739 - llm_backends.cache.disk.DiskCacheStorage - INFO - Attempting to retrieve cache for key: 5e3af4b45da28e76c8c0eb6367819a7def22545a1133e6f6f44606cd9d829c1c\n",
      "2025-07-22 15:26:05,743 - llm_backends.cache.disk.DiskCacheStorage - INFO - Cache hit for key: 5e3af4b45da28e76c8c0eb6367819a7def22545a1133e6f6f44606cd9d829c1c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference completed with 500 responses\n",
      "Total time for inference : 0.0 minutes\n",
      "\n",
      "--- Processing Batch N°5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:26:05,770 - llm_backends.cache.disk.DiskCacheStorage - INFO - Attempting to retrieve cache for key: 469837e2f65cd6f51db3aa3a6cef401b896ed1e4ea25b8155e27a47fceee12b0\n",
      "2025-07-22 15:26:05,775 - llm_backends.cache.disk.DiskCacheStorage - INFO - Cache hit for key: 469837e2f65cd6f51db3aa3a6cef401b896ed1e4ea25b8155e27a47fceee12b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  62%|██████▎   | 5/8 [00:00<00:00, 20.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference completed with 500 responses\n",
      "Total time for inference : 0.0 minutes\n",
      "\n",
      "--- Processing Batch N°6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:26:05,803 - llm_backends.cache.disk.DiskCacheStorage - INFO - Attempting to retrieve cache for key: fa975d595c6884d27ee784ba69052849a1e03fb64ffc5738b993b8cac49cdba5\n",
      "2025-07-22 15:26:05,807 - llm_backends.cache.disk.DiskCacheStorage - INFO - Cache hit for key: fa975d595c6884d27ee784ba69052849a1e03fb64ffc5738b993b8cac49cdba5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference completed with 500 responses\n",
      "Total time for inference : 0.0 minutes\n",
      "\n",
      "--- Processing Batch N°7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:26:05,837 - llm_backends.cache.disk.DiskCacheStorage - INFO - Attempting to retrieve cache for key: b570ab7c65b9b06fbaaad1cfcd4b406ffe001e0fca00f4aa8a3ee767a26d75e6\n",
      "2025-07-22 15:26:05,844 - llm_backends.cache.disk.DiskCacheStorage - INFO - Cache hit for key: b570ab7c65b9b06fbaaad1cfcd4b406ffe001e0fca00f4aa8a3ee767a26d75e6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference completed with 500 responses\n",
      "Total time for inference : 0.0 minutes\n",
      "\n",
      "--- Processing Batch N°8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:26:05,880 - llm_backends.cache.disk.DiskCacheStorage - INFO - Attempting to retrieve cache for key: 1d22dcbaca4d391235337e40f818353259eac2bc2350fa7179b19beb1c00c68a\n",
      "2025-07-22 15:26:05,884 - llm_backends.cache.disk.DiskCacheStorage - INFO - Cache hit for key: 1d22dcbaca4d391235337e40f818353259eac2bc2350fa7179b19beb1c00c68a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 8/8 [00:00<00:00, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference completed with 253 responses\n",
      "Total time for inference : 0.0 minutes\n",
      "\n",
      "--> Total computation time for all batches: 0.0 minutes <--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Precompute a mapping from custom_id to prompt object\n",
    "prompt_map = {p[\"custom_id\"]: p for p in prompts_items}\n",
    "\n",
    "batch_number = 1\n",
    "batch_llm_responses_list = []\n",
    "initial_time = time.time()\n",
    "\n",
    "for batch_raw_responses in tqdm(batch_raw_responses_list, desc=\"Processing batches\"):\n",
    "    print(f\"--- Processing Batch N°{batch_number} ---\")\n",
    "    start_time = time.time()\n",
    "    llm_responses = []\n",
    "    inference_number = 1\n",
    "    for raw_response in tqdm(batch_raw_responses, desc=f\"Batch {batch_number} processing\", leave=False):\n",
    "        custom_id = raw_response.get(\"custom_id\", \"\")\n",
    "        prompt_obj = prompt_map.get(custom_id)\n",
    "        if prompt_obj:\n",
    "            prompt_response_records.append({\n",
    "                \"custom_id\": custom_id,\n",
    "                \"registry_id\": prompt_obj[\"registry_id\"],\n",
    "                \"publi_id\": prompt_obj[\"publi_id\"],\n",
    "                \"prompt\": prompt_obj[\"prompt\"],\n",
    "                \"llm_response\": raw_response,\n",
    "            })\n",
    "            # Parse raw response and add additional info\n",
    "            parsed_response = backend._parse_response(raw_response)\n",
    "            parsed_response[\"custom_id\"] = custom_id\n",
    "            parsed_response[\"registry_id\"] = prompt_obj[\"registry_id\"]\n",
    "            parsed_response[\"publi_id\"] = prompt_obj[\"publi_id\"]\n",
    "            llm_responses.append(parsed_response)\n",
    "        inference_number += 1\n",
    "    \n",
    "    elapsed_total = (time.time() - start_time) / 60  # Convert to minutes\n",
    "    print(f\"Batch inference completed with {len(llm_responses)} responses\")\n",
    "    print(f\"Total time for inference : {elapsed_total:.1f} minutes\\n\")\n",
    "    batch_llm_responses_list.append(llm_responses)\n",
    "    batch_number += 1\n",
    "\n",
    "total_computation_time = (time.time() - initial_time) / 60  # Convert to minutes\n",
    "print(f\"--> Total computation time for all batches: {total_computation_time:.1f} minutes <--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "79aacf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_string(string):\n",
    "    \"\"\"Format string to remove unwanted characters.\"\"\"\n",
    "    # remove punctuation and special characters, lower case\n",
    "    return ''.join(e for e in string if e.isalnum() or e.isspace()).lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "103c2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all european countries from west to east\n",
    "european_countries = [\n",
    "    \"albania\",\n",
    "    \"andorra\",\n",
    "    \"armenia\",\n",
    "    \"austria\",\n",
    "    \"azerbaijan\",\n",
    "    \"belarus\",\n",
    "    \"belgium\",\n",
    "    \"bosnia and herzegovina\",\n",
    "    \"bulgaria\",\n",
    "    \"croatia\",\n",
    "    \"cyprus\",\n",
    "    \"czech republic\",\n",
    "    \"denmark\",\n",
    "    \"estonia\",\n",
    "    \"finland\",\n",
    "    \"france\",\n",
    "    \"georgia\",\n",
    "    \"germany\",\n",
    "    \"greece\",\n",
    "    \"hungary\",\n",
    "    \"iceland\",\n",
    "    \"ireland\",\n",
    "    \"italy\",\n",
    "    \"kazakhstan\",  # part of it in Europe\n",
    "    \"kosovo\",\n",
    "    \"latvia\",\n",
    "    \"liechtenstein\",\n",
    "    \"lithuania\",\n",
    "    \"luxembourg\",\n",
    "    \"malta\",\n",
    "    \"moldova\",  # part of it in Europe\n",
    "    \"monaco\",\n",
    "    \"montenegro\",\n",
    "    \"netherlands\",\n",
    "    \"north macedonia\",  # part of it in Europe\n",
    "    \"norway\",  # part of it in Europe\n",
    "    \"poland\",\n",
    "    \"portugal\",\n",
    "    \"romania\",\n",
    "    \"russia\",  # part of it in Europe\n",
    "    \"san marino\",\n",
    "    \"serbia\",\n",
    "    \"slovakia\",\n",
    "    \"slovenia\",\n",
    "    \"spain\",\n",
    "    \"sweden\",\n",
    "    \"switzerland\",\n",
    "    \"turkey\",  # part of it in Europe\n",
    "    \"ukraine\",\n",
    "    \"uk\",\n",
    "    \"united kingdom\",\n",
    "    \"scotland\",\n",
    "    \"wales\",\n",
    "    \"england\",\n",
    "    \"northern ireland\",\n",
    "    \"great britain\",\n",
    "    \"europe\",\n",
    "    \"european union\",\n",
    "]\n",
    "\n",
    "# select only the registries that have a geographical area in the list of european countries\n",
    "european_countries_set = set(format_string(country) for country in european_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ce7bff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all countries\n",
    "countries = list(pycountry.countries)\n",
    "\n",
    "# Display country names\n",
    "country_names = [country.name for country in countries]\n",
    "# complete with some geogrpahical areas such as coontinents, Scandinavia or other\n",
    "geo_areas_list = [\n",
    "    \"Europe\",\n",
    "    \"European Union\",\n",
    "    \"Great Britain\"\n",
    "    \"Asia\",\n",
    "    \"Africa\",\n",
    "    \"America\",\n",
    "    \"North America\",\n",
    "    \"South America\",\n",
    "    \"Oceania\",\n",
    "    \"Scandinavia\",\n",
    "    \"Middle East\",\n",
    "    \"Caribbean\",\n",
    "    \"Central America\",\n",
    "    \"Eastern Europe\",\n",
    "    \"Western Europe\",\n",
    "    \"Northern Europe\",\n",
    "    \"Southern Europe\",\n",
    "    \"Central Asia\",\n",
    "    \"South Asia\",\n",
    "    \"Southeast Asia\",\n",
    "    \"East Asia\",\n",
    "    \"Western Asia\",\n",
    "    \"North Africa\",\n",
    "    \"Sub-Saharan Africa\",\n",
    "    \"Latin America\",\n",
    "    \"International\",\n",
    "    \"Multinational\",\n",
    "    \"Worldwide\",\n",
    "]\n",
    "all_geo_areas = set(country_names + geo_areas_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f8e6a99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registry ID: 820, Geographical Area: ['America', 'United States', 'Canada', 'Multinational']\n",
      "- Is European: False,\n",
      "- Is Multinational: True,\n",
      "- Is International: False,\n",
      "- Is Worldwide: False\n",
      "\n",
      "Registry ID: 128, Geographical Area: ['Sweden', 'Norway', 'Finland', 'Denmark', 'Multinational', 'Scandinavia']\n",
      "- Is European: True,\n",
      "- Is Multinational: True,\n",
      "- Is International: False,\n",
      "- Is Worldwide: False\n",
      "\n",
      "Registry ID: 2940, Geographical Area: ['United Kingdom']\n",
      "- Is European: True,\n",
      "- Is Multinational: False,\n",
      "- Is International: False,\n",
      "- Is Worldwide: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set a new key \"European\" set to false tp all registries in the registry_dataset\n",
    "for registry in registry_dataset:\n",
    "    registry[\"geographical_area\"] = []  # Initialize geographical_area as an empty list\n",
    "    registry[\"is_european\"] = False  # Initialize is_european as False\n",
    "    registry[\"is_multinational\"] = False  # Initialize is_multinational as False\n",
    "    registry[\"is_international\"] = False  # Initialize is_international as False\n",
    "    registry[\"is_worldwide\"] = False  # Initialize is_worldwide as False\n",
    "\n",
    "# now update geographical_area (list) of each registry of registry_dataset with the llm_responses (list of all reponses related to this specific registry)\n",
    "for llm_responses in batch_llm_responses_list:\n",
    "    if not llm_responses:\n",
    "        continue  # Skip empty response batches\n",
    "    for response in llm_responses:\n",
    "        registry_id = response.get(\"registry_id\", \"\")\n",
    "        geographical_area = response.get(\"geographical_area\", None) # a string of multiple geo areas separated by commas\n",
    "        if geographical_area:\n",
    "            # Find the registry in the original dataset and update its geographical_area\n",
    "            for registry in registry_dataset:\n",
    "                if registry[\"object_id\"] == registry_id:\n",
    "                    # format the response string geographical_area, and when a substring of it is in the european_registries_set, and not already in the geographical_area list, then append the found european country to the geographical_area list\n",
    "                    for region in all_geo_areas:\n",
    "                        if format_string(region) in format_string(geographical_area):\n",
    "                            if region not in registry[\"geographical_area\"]:\n",
    "                                registry[\"geographical_area\"].append(region.title())\n",
    "                            if format_string(region) in european_countries_set and not registry[\"is_european\"]:\n",
    "                                registry[\"is_european\"] = True\n",
    "                    # Check for multinational, international, or worldwide and update\n",
    "                    if \"multinational\" in format_string(geographical_area) and not registry[\"is_multinational\"]:\n",
    "                        registry[\"is_multinational\"] = True\n",
    "                    if \"international\" in format_string(geographical_area) and not registry[\"is_international\"]:\n",
    "                        registry[\"is_international\"] = True\n",
    "                    if \"worldwide\" in format_string(geographical_area) and not registry[\"is_worldwide\"]:\n",
    "                        registry[\"is_worldwide\"] = True\n",
    "\n",
    "\n",
    "# show result for first 3 registries\n",
    "for registry in registry_dataset[:3]:\n",
    "    print(f\"Registry ID: {registry['object_id']}, Geographical Area: {registry.get('geographical_area', [])}\")\n",
    "    print(f\"- Is European: {registry.get('is_european', False)},\\n\"\n",
    "          f\"- Is Multinational: {registry.get('is_multinational', False)},\\n\"\n",
    "          f\"- Is International: {registry.get('is_international', False)},\\n\"\n",
    "          f\"- Is Worldwide: {registry.get('is_worldwide', False)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3c864231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publication ID: 0010390c-e875-510a-a898-4f296e4a294a, Geographical Area: ['Sweden']\n",
      "Publication ID: 001772e5-c3ba-5732-89fe-1d235cf3aef6, Geographical Area: ['Netherlands']\n",
      "Publication ID: 00353829-eeef-56a0-a79d-8f55d47eb8dc, Geographical Area: ['Australia']\n"
     ]
    }
   ],
   "source": [
    "# Now update geographical_area (list) of each publication of publis_dataset with the llm_responses (list of all responses related to this specific publication)\n",
    "# But this time it can be any country, not only european countries\n",
    "for llm_responses in batch_llm_responses_list:\n",
    "    if not llm_responses:\n",
    "        continue  # Skip empty response batches\n",
    "    for response in llm_responses:\n",
    "        # registry_id = response.get(\"registry_id\", \"\")\n",
    "        geographical_area = response.get(\"geographical_area\", None)  # a string of multiple geo areas separated by commas\n",
    "        # once extracted, it is going to be updated, so first make it empty\n",
    "        # make response geo area empty\n",
    "        response[\"geographical_area\"] = []\n",
    "        if geographical_area:\n",
    "            # Find the publication in the original dataset and update its geographical_area\n",
    "            for publication in publis_dataset:\n",
    "                if publication[\"object_id\"] == response.get(\"publi_id\", \"\"):\n",
    "                    # set its geographical_area to an empty list\n",
    "                    publication[\"geographical_area\"] = []\n",
    "                    # format the response string geographical_area, and when a substring of it is not already in the geographical_area list, then append the found country to the geographical_area list\n",
    "                    for region in all_geo_areas:\n",
    "                        if format_string(region) in format_string(geographical_area):\n",
    "                            if region not in publication[\"geographical_area\"]:\n",
    "                                publication[\"geographical_area\"].append(region.title())\n",
    "\n",
    "# show result for first 3 publications\n",
    "for publication in publis_dataset[:3]:\n",
    "    print(f\"Publication ID: {publication['object_id']}, Geographical Area: {publication.get('geographical_area', [])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2aef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = working_dir + \"/data/from_notebooks/NW02/R03_update_geo_areas/dedup_100_famous_european_registries_with_geo_area.json\"\n",
    "# make sure the output directory exists\n",
    "output_dir = Path(output_file_path).parent\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# save in projects/P04_official_reg_db_creation/data/from_notebooks/NW02/R02_create_dataset_dedup/test/dedup_100_famous_european_registries.json\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(registry_dataset, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9526b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this file as famous_european_registries_sample_publi_data/{batch_number}.json wwith batch size of 500\n",
    "output_folder = working_dir + \"/data/from_notebooks/NW02/R03_update_geo_areas/famous_european_reg_publi_data_with_geo_area\"\n",
    "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "for i in range(0, len(publis_dataset), 500):\n",
    "    batch = publis_dataset[i:i + 500]\n",
    "    batch_number = i // 500 + 1\n",
    "    file_name = f\"{batch_number}.json\"\n",
    "    output_file_path = os.path.join(output_folder, file_name)\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(batch, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "881a0ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registry Dataset with Geographical Areas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registry_name</th>\n",
       "      <th>geographical_area</th>\n",
       "      <th>is_european</th>\n",
       "      <th>is_multinational</th>\n",
       "      <th>is_international</th>\n",
       "      <th>is_worldwide</th>\n",
       "      <th>number_of_occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get With The Guidelines-Resuscitation</td>\n",
       "      <td>[America, United States, Canada, Multinational]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swedish National Inpatient Register</td>\n",
       "      <td>[Sweden, Norway, Finland, Denmark, Multination...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>National Registry for Radiation Workers</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>National Pathology Registry</td>\n",
       "      <td>[Denmark, Australia, Netherlands]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swedish Registry for Cognitive/Dementia Disorders</td>\n",
       "      <td>[Sweden]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>National Death Index</td>\n",
       "      <td>[Australia, America, United States, Spain]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Netherlands Heart Registration</td>\n",
       "      <td>[Netherlands]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Côte d'Or Breast Cancer Registry</td>\n",
       "      <td>[France]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Swedish Coronary Angiography and Angioplasty R...</td>\n",
       "      <td>[Sweden]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>South-Verona Psychiatric Case Register</td>\n",
       "      <td>[Italy]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Victorian Cancer Registry</td>\n",
       "      <td>[Australia]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UK Transplant Registry</td>\n",
       "      <td>[United Kingdom, Ireland]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Swedish Vascular Registry</td>\n",
       "      <td>[Sweden]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RIETE Registry</td>\n",
       "      <td>[France, Greece, Belgium, United Kingdom, Swit...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>North American Association of Central Cancer R...</td>\n",
       "      <td>[North America, Canada, America, United States...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>COVID-19 and Cancer Consortium registry</td>\n",
       "      <td>[America, United States, Canada, Multinational...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>European Renal Association-European Dialysis a...</td>\n",
       "      <td>[Europe, Multinational, Greece, Belgium, Norwa...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>European Acquired Haemophilia Registry</td>\n",
       "      <td>[Europe, Multinational, Finland, Denmark, Esto...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Italian Twin Registry</td>\n",
       "      <td>[Italy]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Danish National Diabetes Register</td>\n",
       "      <td>[Denmark]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Intestinal Transplant Registry</td>\n",
       "      <td>[International, Worldwide, Europe, America, Un...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Norwegian Breast Cancer Screening Program</td>\n",
       "      <td>[Norway]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Swedish Pregnancy Register</td>\n",
       "      <td>[Sweden, Norway, Multinational]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Enroll-HD</td>\n",
       "      <td>[Europe, International, Poland, Worldwide, Mul...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Secure Anonymised Information Linkage Databank</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Australian National Creutzfeldt-Jakob disease ...</td>\n",
       "      <td>[Australia]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dutch Polyposis Registry</td>\n",
       "      <td>[Netherlands]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Myocardial Infarction Triage and Intervention ...</td>\n",
       "      <td>[America, United States]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>National Cancer Registry of Ireland</td>\n",
       "      <td>[Ireland]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Swedish National Cervical Screening Registry</td>\n",
       "      <td>[Sweden]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        registry_name  \\\n",
       "0               Get With The Guidelines-Resuscitation   \n",
       "1                 Swedish National Inpatient Register   \n",
       "2             National Registry for Radiation Workers   \n",
       "3                         National Pathology Registry   \n",
       "4   Swedish Registry for Cognitive/Dementia Disorders   \n",
       "5                                National Death Index   \n",
       "6                      Netherlands Heart Registration   \n",
       "7                    Côte d'Or Breast Cancer Registry   \n",
       "8   Swedish Coronary Angiography and Angioplasty R...   \n",
       "9              South-Verona Psychiatric Case Register   \n",
       "10                          Victorian Cancer Registry   \n",
       "11                             UK Transplant Registry   \n",
       "12                          Swedish Vascular Registry   \n",
       "13                                     RIETE Registry   \n",
       "14  North American Association of Central Cancer R...   \n",
       "15            COVID-19 and Cancer Consortium registry   \n",
       "16  European Renal Association-European Dialysis a...   \n",
       "17             European Acquired Haemophilia Registry   \n",
       "18                              Italian Twin Registry   \n",
       "19                  Danish National Diabetes Register   \n",
       "20                     Intestinal Transplant Registry   \n",
       "21          Norwegian Breast Cancer Screening Program   \n",
       "22                         Swedish Pregnancy Register   \n",
       "23                                          Enroll-HD   \n",
       "24     Secure Anonymised Information Linkage Databank   \n",
       "25  Australian National Creutzfeldt-Jakob disease ...   \n",
       "26                           Dutch Polyposis Registry   \n",
       "27  Myocardial Infarction Triage and Intervention ...   \n",
       "28                National Cancer Registry of Ireland   \n",
       "29       Swedish National Cervical Screening Registry   \n",
       "\n",
       "                                    geographical_area  is_european  \\\n",
       "0     [America, United States, Canada, Multinational]        False   \n",
       "1   [Sweden, Norway, Finland, Denmark, Multination...         True   \n",
       "2                                    [United Kingdom]         True   \n",
       "3                   [Denmark, Australia, Netherlands]         True   \n",
       "4                                            [Sweden]         True   \n",
       "5          [Australia, America, United States, Spain]         True   \n",
       "6                                       [Netherlands]         True   \n",
       "7                                            [France]         True   \n",
       "8                                            [Sweden]         True   \n",
       "9                                             [Italy]         True   \n",
       "10                                        [Australia]        False   \n",
       "11                          [United Kingdom, Ireland]         True   \n",
       "12                                           [Sweden]         True   \n",
       "13  [France, Greece, Belgium, United Kingdom, Swit...         True   \n",
       "14  [North America, Canada, America, United States...        False   \n",
       "15  [America, United States, Canada, Multinational...         True   \n",
       "16  [Europe, Multinational, Greece, Belgium, Norwa...         True   \n",
       "17  [Europe, Multinational, Finland, Denmark, Esto...         True   \n",
       "18                                            [Italy]         True   \n",
       "19                                          [Denmark]         True   \n",
       "20  [International, Worldwide, Europe, America, Un...         True   \n",
       "21                                           [Norway]         True   \n",
       "22                    [Sweden, Norway, Multinational]         True   \n",
       "23  [Europe, International, Poland, Worldwide, Mul...         True   \n",
       "24                                   [United Kingdom]         True   \n",
       "25                                        [Australia]        False   \n",
       "26                                      [Netherlands]         True   \n",
       "27                           [America, United States]        False   \n",
       "28                                          [Ireland]         True   \n",
       "29                                           [Sweden]         True   \n",
       "\n",
       "    is_multinational  is_international  is_worldwide  number_of_occurrences  \n",
       "0               True             False         False                     86  \n",
       "1               True             False         False                     53  \n",
       "2              False             False         False                     19  \n",
       "3              False             False         False                     11  \n",
       "4              False             False         False                     12  \n",
       "5              False             False         False                    109  \n",
       "6              False             False         False                     26  \n",
       "7              False             False         False                     10  \n",
       "8              False             False         False                     10  \n",
       "9              False             False         False                     16  \n",
       "10             False             False         False                    109  \n",
       "11             False             False         False                    140  \n",
       "12             False             False         False                     89  \n",
       "13              True              True         False                     28  \n",
       "14              True             False         False                     42  \n",
       "15              True              True         False                     12  \n",
       "16              True              True         False                     71  \n",
       "17              True             False         False                     13  \n",
       "18             False             False         False                     36  \n",
       "19             False             False         False                     17  \n",
       "20              True              True          True                     26  \n",
       "21             False             False         False                     27  \n",
       "22              True             False         False                     37  \n",
       "23              True              True          True                     36  \n",
       "24             False             False         False                     12  \n",
       "25             False             False         False                     32  \n",
       "26             False             False         False                     11  \n",
       "27             False             False         False                     19  \n",
       "28             False             False         False                     40  \n",
       "29             False             False         False                     27  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display first 30 items of registry_dataset with columns 'registry_name', 'geographical_area', 'is_european', 'is_multinational', 'is_international', 'is_worldwide', 'number_of_occurrences'\n",
    "df_registry = pd.DataFrame(registry_dataset)\n",
    "print(\"Registry Dataset with Geographical Areas:\")\n",
    "display(df_registry[[\"registry_name\", \"geographical_area\", \"is_european\", \"is_multinational\", \"is_international\", \"is_worldwide\", \"number_of_occurrences\"]].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "15a22513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total European Registries: 83\n",
      "Total Multinational Registries: 21\n",
      "Total International Registries: 9\n",
      "Total Worldwide Registries: 3\n"
     ]
    }
   ],
   "source": [
    "# count how many are european, multinational, international, worldwide\n",
    "european_count = sum(1 for r in registry_dataset if r.get(\"is_european\", False))\n",
    "multinational_count = sum(1 for r in registry_dataset if r.get(\"is_multinational\", False))\n",
    "international_count = sum(1 for r in registry_dataset if r.get(\"is_international\", False))\n",
    "worldwide_count = sum(1 for r in registry_dataset if r.get(\"is_worldwide\", False))\n",
    "print(f\"Total European Registries: {european_count}\")\n",
    "print(f\"Total Multinational Registries: {multinational_count}\")\n",
    "print(f\"Total International Registries: {international_count}\")\n",
    "print(f\"Total Worldwide Registries: {worldwide_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P04_official_reg_db_creation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
