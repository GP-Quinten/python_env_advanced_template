{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa75539",
   "metadata": {},
   "source": [
    "# Grid Search for Best Epsilon Configuration\n",
    "This notebook performs a grid search over multiple epsilon values for HDBSCAN clustering, evaluating each configuration on two datasets and saving the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2119f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to /home/gpinon/more_europa/clean_rdc_experiments/projects/P05_refine_dedup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.pyenv/versions/3.11.11/envs/P05_refine_dedup_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Set working directory (adjust if needed)\n",
    "working_dir = '/home/gpinon/more_europa/clean_rdc_experiments/projects/P05_refine_dedup'\n",
    "os.chdir(working_dir)\n",
    "print(f'Changed working directory to {working_dir}')\n",
    "from src.p05_refine_dedup import config\n",
    "from src.p05_refine_dedup.utils.utils import (\n",
    "    is_noise,\n",
    "    run_hdbscan,\n",
    "    apply_predictions,\n",
    "    compute_metrics,\n",
    ")\n",
    "from src.p05_refine_dedup.utils.s3_io_functions import (\n",
    "    load_parquet_from_s3,\n",
    ")\n",
    "\n",
    "output_dir = Path(\"data/W03/from_notebooks/R06_additional_grid_search/v3\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_xlsx = output_dir / 'grid_search_results.xlsx'\n",
    "best_config_json = output_dir / 'best_config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cabcf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data will be loaded from s3://s3-common-dev20231214174437248800000002/registry_data_catalog_experiments/P05_refine_dedup/registry_names_embeddings.parquet\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings\n",
    "s3_input_embeddings = 'registry_data_catalog_experiments/P05_refine_dedup/registry_names_embeddings.parquet'\n",
    "bucket_name = config.BUCKET_NAME_DEV\n",
    "folder_path = s3_input_embeddings.rsplit('/', 1)[0]\n",
    "file_name = s3_input_embeddings.rsplit('/', 1)[-1]\n",
    "embeddings_df = load_parquet_from_s3(\n",
    "    bucket_name=bucket_name,\n",
    "    folder_path=folder_path,\n",
    "    file_name=file_name,\n",
    ")\n",
    "clusters_table_xlsx = 'data/W02/R02_evaluate_model_performance/clusters_table.xlsx'\n",
    "clusters_df = pd.read_excel(clusters_table_xlsx)\n",
    "clusters_df = clusters_df.merge(\n",
    "    embeddings_df[['full_name', 'full_name_embedding']],\n",
    "    on='full_name',\n",
    "    how='left'\n",
    ")\n",
    "clusters_df.rename(columns={'Final_Cluster': 'cluster_0'}, inplace=True)\n",
    "\n",
    "evaluation_dataset_any = 'data/W01/R03_eval_pairs_similarity_assessment_with_llm/gpt4_1_openai/assessed_pairs_v1.xlsx'\n",
    "evaluation_dataset_famous = 'data/W01/R03_eval_pairs_similarity_assessment_with_llm/gpt4_1_openai/famous_close_assessed_pairs_v1.xlsx'\n",
    "eval_df_any = pd.read_excel(evaluation_dataset_any)\n",
    "eval_df_famous = pd.read_excel(evaluation_dataset_famous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27b9e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define epsilon ranges for each cluster type\n",
    "eps_grid = {\n",
    "    # '0_0': np.arange(0.44, 0.51, 0.01),\n",
    "    'start_0_': np.arange(0.34, 0.44, 0.01),\n",
    "    # 'end__0': np.arange(0.28, 0.33, 0.01),\n",
    "    'other': np.arange(0.19, 0.27, 0.01),\n",
    "}\n",
    "# convert array to list of str()\n",
    "for key in eps_grid:\n",
    "    eps_grid[key] = [str(round(x, 2)) for x in eps_grid[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60568134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to get epsilon for a cluster given the current config\n",
    "def get_epsilon(cluster_id, eps_config):\n",
    "    if cluster_id == '0_0':\n",
    "        return eps_config['0_0']\n",
    "    elif cluster_id.startswith('0_'):\n",
    "        return eps_config['start_0_']\n",
    "    elif cluster_id.endswith('_0'):\n",
    "        return eps_config['end__0']\n",
    "    else:\n",
    "        return eps_config['other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2773674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one dictionary of new cluseters ids for each cluster type\n",
    "# dict_0_0 = {\n",
    "#     0.44:[\n",
    "#         {'full_name': 'name_1',\n",
    "#          'cluster_0': '0_0',\n",
    "#          'subcluster': '0',\n",
    "#          'cluster_1': '0_0_0'\n",
    "#          },\n",
    "#         {'full_name': 'name_1',\n",
    "#          'cluster_0': '0_0',\n",
    "#          'subcluster': '1',\n",
    "#          'cluster_1': '0_0_1'\n",
    "#          },\n",
    "#          {'full_name': 'name_2',\n",
    "#           'cluster_0': '0_0',\n",
    "#           'subcluster': '2',\n",
    "#           'cluster_1': '0_0_2'\n",
    "#           }\n",
    "#           ...\n",
    "#          ],\n",
    "#     0.45:[\n",
    "#         {'full_name': 'name_1',\n",
    "#          'cluster_0': '0_0',\n",
    "#          'subcluster': '0',\n",
    "#          'cluster_1': '0_0_0'\n",
    "#          },\n",
    "#         {'full_name': 'name_1',\n",
    "#          'cluster_0': '0_0',\n",
    "#          'subcluster': '1',\n",
    "#          'cluster_1': '0_0_1'\n",
    "#          },\n",
    "#          {'full_name': 'name_2',\n",
    "#           'cluster_0': '0_0',\n",
    "#           'subcluster': '2',\n",
    "#           'cluster_1': '0_0_2'\n",
    "#           }\n",
    "#           ...\n",
    "#          ],\n",
    "#     ...\n",
    "# }\n",
    "def filter_on_cluster_type(clusters_df, cluster_type):\n",
    "    if cluster_type == '0_0':\n",
    "        return clusters_df[clusters_df['cluster_0'] == cluster_type]\n",
    "    elif cluster_type == 'start_0_':\n",
    "        # starting with '0_' and not ending with '_0'\n",
    "        return clusters_df[(clusters_df['cluster_0'].str.startswith('0_')) &\n",
    "                           (~clusters_df['cluster_0'].str.endswith('_0'))]\n",
    "    elif cluster_type == 'end__0':\n",
    "        # ending with '_0' and not starting with '0_'\n",
    "        return clusters_df[clusters_df['cluster_0'].str.endswith('_0') &\n",
    "                           (~clusters_df['cluster_0'].str.startswith('0_'))]\n",
    "    elif cluster_type == 'other':\n",
    "        return clusters_df[~clusters_df['cluster_0'].str.startswith('0_') &\n",
    "                           ~clusters_df['cluster_0'].str.endswith('_0')]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown cluster type: {cluster_type}\")\n",
    "\n",
    "# Initiate dict_0_0 with all espilons and full_name and cluster_0 only\n",
    "def create_initial_dict(clusters_df, cluster_type):\n",
    "    initial_dict = {}\n",
    "    for eps in eps_grid[cluster_type]:\n",
    "        clusters_df_filtered = filter_on_cluster_type(clusters_df, cluster_type)\n",
    "        initial_dict[eps] = clusters_df_filtered[['full_name', 'cluster_0']].copy()\n",
    "        # set subcluster and cluster_1 to None\n",
    "        initial_dict[eps]['subcluster'] = None\n",
    "        initial_dict[eps]['cluster_1'] = None\n",
    "    return initial_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5de6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = 20\n",
    "large_clusters = clusters_df['cluster_0'].value_counts()[clusters_df['cluster_0'].value_counts() >= n_max].index.tolist()\n",
    "# filter on large clusters\n",
    "large_clusters_df = clusters_df[clusters_df['cluster_0'].isin(large_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27465cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate dictionaries for each cluster type\n",
    "# dict_0_0 = create_initial_dict(large_clusters_df, '0_0')\n",
    "dict_start_0_ = create_initial_dict(large_clusters_df, 'start_0_')\n",
    "# dict_end__0 = create_initial_dict(large_clusters_df, 'end__0')\n",
    "dict_other = create_initial_dict(large_clusters_df, 'other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fd6d7",
   "metadata": {},
   "source": [
    "# prepare dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d3ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size=1\n",
    "min_samples=1\n",
    "# cluster_selection_epsilon=0.0\n",
    "max_cluster_size=30\n",
    "metric=\"euclidean\"\n",
    "n_jobs=-1\n",
    "cluster_selection_method=\"leaf\"\n",
    "store_centers=\"medoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2af310ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_clusters(clusters_df, cluster_type, results_dict):\n",
    "    # first filter on cluster type\n",
    "    clusters_df_filtered = filter_on_cluster_type(clusters_df, cluster_type)\n",
    "    # # test on 100 data points\n",
    "    # clusters_df_filtered = clusters_df_filtered.head(1000) # For testing, remove this line for full dataset\n",
    "    # retrive the list of clusters in cluster_0\n",
    "    clusters = clusters_df_filtered['cluster_0'].unique().tolist()\n",
    "\n",
    "    for eps in tqdm(eps_grid[cluster_type], desc=f\"Processing {cluster_type} clusters\"):\n",
    "        for cluster in clusters:\n",
    "            # first filter on this cluster\n",
    "            df = clusters_df_filtered[clusters_df_filtered['cluster_0'] == cluster].copy()\n",
    "            embeddings = np.vstack(df['full_name_embedding'].values)\n",
    "\n",
    "            # Add subcluster and cluster_1 columns\n",
    "            df['subcluster'] = None\n",
    "            df['cluster_1'] = None\n",
    "            \n",
    "            # Apply HDBSCAN clustering\n",
    "            labels, comp_time = run_hdbscan(\n",
    "                embeddings,\n",
    "                min_cluster_size=min_cluster_size,\n",
    "                min_samples=min_samples,\n",
    "                cluster_selection_epsilon=float(eps),\n",
    "                max_cluster_size=max_cluster_size,\n",
    "                metric=metric,\n",
    "                n_jobs=n_jobs,\n",
    "                cluster_selection_method=cluster_selection_method,\n",
    "                store_centers=store_centers,\n",
    "            )\n",
    "            \n",
    "            df['subcluster'] = labels.astype(str)  # Convert labels to string for subcluster\n",
    "            df['cluster_1'] = df['cluster_0'] + '_' + df['subcluster']\n",
    "\n",
    "            # Vectorized update: set full_name as index for both DataFrames, then update\n",
    "            updates = df[['full_name', 'subcluster', 'cluster_1']].set_index('full_name')\n",
    "            res_df = results_dict[eps].set_index('full_name')\n",
    "            res_df.update(updates)\n",
    "            results_dict[eps] = res_df.reset_index()\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c6f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 0_0 clusters: 100%|██████████| 8/8 [18:44<00:00, 140.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# # test on 100 data points on '0_0' clusters\n",
    "# dict_0_0 = process_clusters(large_clusters_df, '0_0', dict_0_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1afb1bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing start_0_ clusters:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing start_0_ clusters: 100%|██████████| 10/10 [04:12<00:00, 25.24s/it]\n"
     ]
    }
   ],
   "source": [
    "dict_start_0_ = process_clusters(large_clusters_df, 'start_0_', dict_start_0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6286c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing end__0 clusters: 100%|██████████| 5/5 [00:06<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "dict_end__0 = process_clusters(large_clusters_df, 'end__0', dict_end__0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07d9c9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing other clusters: 100%|██████████| 9/9 [00:23<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "dict_other = process_clusters(large_clusters_df, 'other', dict_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4238166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each dictionary to a json file dict_0_0, dict_start_0_, dict_end__0, dict_other\n",
    "# not looping on eps values, save direclty all eps values in on single json file\n",
    "def save_dict_to_json(data_dict, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data_dict, f, indent=4)\n",
    "# # transform each object (dataframe) in the dict to a dict\n",
    "# dict_0_0 = {eps: df.to_dict(orient='records') for eps, df in dict_0_0.items()}\n",
    "dict_start_0_ = {eps: df.to_dict(orient='records') for eps, df in dict_start_0_.items()}\n",
    "dict_end__0 = {eps: df.to_dict(orient='records') for eps, df in dict_end__0.items()}\n",
    "dict_other = {eps: df.to_dict(orient='records') for eps, df in dict_other.items()}\n",
    "\n",
    "# Save dictionaries to json files\n",
    "# save_dict_to_json(dict_0_0, output_dir / 'dict_0_0.json')\n",
    "save_dict_to_json(dict_start_0_, output_dir / 'dict_start_0_.json')\n",
    "# save_dict_to_json(dict_end__0, output_dir / 'dict_end__0.json')\n",
    "save_dict_to_json(dict_other, output_dir / 'dict_other.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b204fb",
   "metadata": {},
   "source": [
    "# compute original metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd02775d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for any pairs: {'precision': 0.72, 'recall': 0.79, 'f1': 0.76, 'accuracy': 0.81}\n",
      "Metrics for famous pairs: {'precision': 0.81, 'recall': 0.77, 'f1': 0.79, 'accuracy': 0.86}\n"
     ]
    }
   ],
   "source": [
    "clusters_df[f\"corrected_cluster\"] = clusters_df[f\"corrected_cluster\"].apply(\n",
    "    lambda x: None if is_noise(x) else x\n",
    ")\n",
    "# recompute current performance metrics\n",
    "cluster_map = dict(zip(clusters_df[\"full_name\"], clusters_df[f\"corrected_cluster\"]))\n",
    "# Apply predictions based on cluster mapping\n",
    "eval_df_any = apply_predictions(\n",
    "    eval_df_any, cluster_map, col_el_1=\"full_name\", col_el_2=\"alias\"\n",
    ")\n",
    "# Compute metrics (assuming ground truth is in column \"final_label\")\n",
    "metrics_any = compute_metrics(eval_df_any[\"final_label\"], eval_df_any[\"prediction\"])\n",
    "# log the metrics with 2 decimal precision\n",
    "metrics_any_to_print = {\n",
    "    k: round(v, 2) if isinstance(v, float) else v for k, v in metrics_any.items()\n",
    "}\n",
    "print(f\"Metrics for any pairs: {metrics_any_to_print}\")\n",
    "\n",
    "# Apply predictions\n",
    "eval_df_famous = apply_predictions(\n",
    "    eval_df_famous, cluster_map, col_el_1=\"full_name\", col_el_2=\"alias\"\n",
    ")\n",
    "metrics_famous = compute_metrics(\n",
    "    eval_df_famous[\"final_label\"], eval_df_famous[\"prediction\"]\n",
    ")\n",
    "# log the metrics with 2 decimal precision\n",
    "metrics_famous_to_print = {\n",
    "    k: round(v, 2) if isinstance(v, float) else v for k, v in metrics_famous.items()\n",
    "}\n",
    "print(f\"Metrics for famous pairs: {metrics_famous_to_print}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc62fc5",
   "metadata": {},
   "source": [
    "# reload an compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e37203c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the dictionaries from json files\n",
    "def load_dict_from_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "output_dir_original = Path(\"data/W03/from_notebooks/R06_additional_grid_search/v2\")\n",
    "# dict_0_0 = load_dict_from_json(output_dir_original / 'dict_0_0.json')\n",
    "dict_start_0_ = load_dict_from_json(output_dir_original / 'dict_start_0_.json')\n",
    "# dict_end__0 = load_dict_from_json(output_dir_original / 'dict_end__0.json')\n",
    "dict_other = load_dict_from_json(output_dir_original / 'dict_other.json')\n",
    "\n",
    "# transform each object (dict) in the dict to a dataframe\n",
    "def transform_dict_to_df(data_dict):\n",
    "    return {eps: pd.DataFrame(records) for eps, records in data_dict.items()}\n",
    "# dict_0_0 = transform_dict_to_df(dict_0_0)\n",
    "dict_start_0_ = transform_dict_to_df(dict_start_0_)\n",
    "# dict_end__0 = transform_dict_to_df(dict_end__0)\n",
    "dict_other = transform_dict_to_df(dict_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8a56624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epsilon combinations:   0%|          | 0/90 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23506/2330050107.py:122: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  grid_search_results = pd.concat(\n",
      "Processing epsilon combinations:   1%|          | 1/90 [00:00<00:49,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New best precision_mean: 0.8 with eps: ('0.34', '0.19')\n",
      "--- New best f1_mean: 0.76 with eps: ('0.34', '0.19')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epsilon combinations:   2%|▏         | 2/90 [00:01<00:48,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New best f1_mean: 0.76 with eps: ('0.34', '0.2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epsilon combinations:   3%|▎         | 3/90 [00:01<00:47,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New best f1_mean: 0.76 with eps: ('0.34', '0.21')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epsilon combinations:   4%|▍         | 4/90 [00:02<00:47,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New best f1_mean: 0.77 with eps: ('0.34', '0.22')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epsilon combinations:   6%|▌         | 5/90 [00:02<00:46,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New best f1_mean: 0.77 with eps: ('0.34', '0.23')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epsilon combinations:   7%|▋         | 6/90 [00:03<00:46,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New best f1_mean: 0.77 with eps: ('0.34', '0.24')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epsilon combinations:   8%|▊         | 7/90 [00:03<00:45,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New best f1_mean: 0.78 with eps: ('0.34', '0.25')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epsilon combinations:   9%|▉         | 8/90 [00:04<00:44,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New best f1_mean: 0.78 with eps: ('0.34', '0.26')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing epsilon combinations: 100%|██████████| 90/90 [00:48<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration: {'eps_start_0_': 0.34, 'eps_other': 0.26, 'f1_mean': 0.78, 'precision_mean': 0.79, 'recall_mean': 0.77, 'f1_any': 0.77, 'precision_any': 0.75, 'recall_any': 0.79, 'f1_famous': 0.79, 'precision_famous': 0.83, 'recall_famous': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initiate grid_search_results with columns eps_0_0, eps_start_0_, eps_end__0, eps_other, f1_any, precision_any, recall_any, f1_famous, precision_famous, recall_famous, f1_mean, precision_mean, recall_mean,\n",
    "grid_search_results = pd.DataFrame(\n",
    "    columns=[\n",
    "        # \"eps_0_0\",\n",
    "        \"eps_start_0_\",\n",
    "        # \"eps_end__0\",\n",
    "        \"eps_other\",\n",
    "        \"f1_any\",\n",
    "        \"precision_any\",\n",
    "        \"recall_any\",\n",
    "        \"f1_famous\",\n",
    "        \"precision_famous\",\n",
    "        \"recall_famous\",\n",
    "        \"f1_mean\",\n",
    "        \"precision_mean\",\n",
    "        \"recall_mean\",\n",
    "    ]\n",
    ")\n",
    "# finally loop on all combiinations of epsilons in all dictionaries\n",
    "from itertools import product\n",
    "\n",
    "# Create a list of all combinations of epsilons\n",
    "eps_combinations = list(\n",
    "    product(\n",
    "        eps_grid[\"start_0_\"], eps_grid[\"other\"]\n",
    "    )\n",
    ") # eps_grid[\"0_0\"], eps_grid[\"end__0\"]\n",
    "best_f1_mean = -1\n",
    "best_precision_mean= -1\n",
    "best_config = None\n",
    "clusters_df[\"subcluster\"] = None\n",
    "clusters_df[\"cluster_1\"] = clusters_df[\"cluster_0\"]\n",
    "clusters_best_config_df = clusters_df.copy()\n",
    "# Loop through each combination of epsilons\n",
    "for eps_combination in tqdm(eps_combinations, desc=\"Processing epsilon combinations\"):\n",
    "    clusters_copy = clusters_df.copy()\n",
    "    clusters_copy = clusters_copy.set_index(\"full_name\")\n",
    "\n",
    "    eps_start_0_, eps_other = eps_combination # eps_0_0, eps_end__0\n",
    "    # Create a new row for the results DataFrame\n",
    "    new_row = {\n",
    "        # \"eps_0_0\": eps_0_0,\n",
    "        \"eps_start_0_\": eps_start_0_,\n",
    "        # \"eps_end__0\": eps_end__0,\n",
    "        \"eps_other\": eps_other,\n",
    "    }\n",
    "\n",
    "    # Update clusters_df with the new cluster_1 and subcluster for all dictionaries matching on 'full_name'\n",
    "    for cluster_type, dict_data, eps in zip(\n",
    "        [\"start_0_\", \"other\"], # \"0_0\", \"end__0\", \n",
    "        [dict_start_0_,dict_other], # dict_0_0,  dict_end__0, \n",
    "        [eps_start_0_, eps_other], # eps_0_0, eps_end__0, \n",
    "    ):\n",
    "        df = dict_data[eps].copy().set_index(\"full_name\")\n",
    "        clusters_copy.update(df[[\"subcluster\", \"cluster_1\"]])\n",
    "\n",
    "    # reset normal index\n",
    "    clusters_copy.reset_index(inplace=True)\n",
    "    \n",
    "    clusters_copy[\"cluster_1\"] = clusters_copy[\"cluster_1\"].apply(\n",
    "        lambda x: None if is_noise(x) else x\n",
    "    )\n",
    "    cluster_map = dict(zip(clusters_copy[\"full_name\"], clusters_copy[\"cluster_1\"]))\n",
    "\n",
    "    # Compute metrics on the updated clusters_df\n",
    "    # Apply predictions\n",
    "    eval_df_any = apply_predictions(\n",
    "        eval_df_any, cluster_map, col_el_1=\"full_name\", col_el_2=\"alias\"\n",
    "    )\n",
    "    metrics_any = compute_metrics(eval_df_any[\"final_label\"], eval_df_any[\"prediction\"])\n",
    "    eval_df_famous = apply_predictions(\n",
    "        eval_df_famous, cluster_map, col_el_1=\"full_name\", col_el_2=\"alias\"\n",
    "    )\n",
    "    metrics_famous = compute_metrics(\n",
    "        eval_df_famous[\"final_label\"], eval_df_famous[\"prediction\"]\n",
    "    )\n",
    "\n",
    "    # Add metrics to the new row\n",
    "    new_row.update(\n",
    "        {\n",
    "            \"f1_any\": metrics_any[\"f1\"],\n",
    "            \"precision_any\": metrics_any[\"precision\"],\n",
    "            \"recall_any\": metrics_any[\"recall\"],\n",
    "            \"f1_famous\": metrics_famous[\"f1\"],\n",
    "            \"precision_famous\": metrics_famous[\"precision\"],\n",
    "            \"recall_famous\": metrics_famous[\"recall\"],\n",
    "            \"f1_mean\": (metrics_any[\"f1\"] + metrics_famous[\"f1\"]) / 2,\n",
    "            \"precision_mean\": (metrics_any[\"precision\"] + metrics_famous[\"precision\"])\n",
    "            / 2,\n",
    "            \"recall_mean\": (metrics_any[\"recall\"] + metrics_famous[\"recall\"]) / 2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Check if this is the best configuration so far. if yes, then update best_config and best_f1_mean\n",
    "    if new_row[\"precision_mean\"] > best_precision_mean:\n",
    "        print(f\"--- New best precision_mean: {round(new_row['precision_mean'],2)} with eps: {eps_combination}\")\n",
    "        best_precision_mean = new_row[\"precision_mean\"]\n",
    "        \n",
    "    if new_row[\"f1_mean\"] > best_f1_mean:\n",
    "        print(f\"--- New best f1_mean: {round(new_row['f1_mean'],2)} with eps: {eps_combination}\")\n",
    "        clusters_best_config_df = clusters_copy.copy()\n",
    "        best_f1_mean = new_row[\"f1_mean\"]\n",
    "        best_config = {\n",
    "            # \"eps_0_0\": eps_0_0,\n",
    "            \"eps_start_0_\": eps_start_0_,\n",
    "            # \"eps_end__0\": eps_end__0,\n",
    "            \"eps_other\": eps_other,\n",
    "            \"f1_mean\": best_f1_mean,\n",
    "            \"precision_mean\": new_row[\"precision_mean\"],\n",
    "            \"recall_mean\": new_row[\"recall_mean\"],\n",
    "            \"f1_any\": new_row[\"f1_any\"],\n",
    "            \"precision_any\": new_row[\"precision_any\"],\n",
    "            \"recall_any\": new_row[\"recall_any\"],\n",
    "            \"f1_famous\": new_row[\"f1_famous\"],\n",
    "            \"precision_famous\": new_row[\"precision_famous\"],\n",
    "            \"recall_famous\": new_row[\"recall_famous\"],\n",
    "        }\n",
    "        # convert all values in best_config to float with 2 decimal places\n",
    "        best_config = {k: round(float(v), 2) for k, v in best_config.items()}\n",
    "\n",
    "    # Append the new row to the results DataFrame\n",
    "    grid_search_results = pd.concat(\n",
    "        [grid_search_results, pd.DataFrame([new_row])],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "# Save grid search results to Excel\n",
    "grid_search_results.to_excel(results_xlsx, index=False)\n",
    "# print and save best configuration to JSON\n",
    "print(f\"Best configuration: {best_config}\")\n",
    "with open(best_config_json, 'w') as f:\n",
    "    json.dump(best_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6739ca73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>number_of_occurrences</th>\n",
       "      <th>cluster_0</th>\n",
       "      <th>corrected_cluster</th>\n",
       "      <th>full_name_embedding</th>\n",
       "      <th>subcluster</th>\n",
       "      <th>cluster_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spanish ABPM Registry (ABPM)</td>\n",
       "      <td>12</td>\n",
       "      <td>1_1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>[-0.035308838, -0.005203247, 0.026031494, -0.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fasa Registry for Systolic Heart Failure (FARSH)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.03074646, 0.028259277, 0.022598267, -0.019...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnCovid Registry (OnCovid)</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.019241333, -0.008605957, 0.04559326, -0.01...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York State Cancer Registry (NYSCR)</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.0053710938, 0.018249512, 0.044647217, -0.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China Liver Transplant Registry (CLTR)</td>\n",
       "      <td>39</td>\n",
       "      <td>5_1</td>\n",
       "      <td>5_1</td>\n",
       "      <td>[-0.03540039, 0.009819031, -0.0044784546, -0.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CMR-COVID (CMR-COVID)</td>\n",
       "      <td>2</td>\n",
       "      <td>0_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.034179688, 0.0039596558, 0.05001831, -0.02...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SAR-COVID (SAR-COVID)</td>\n",
       "      <td>3</td>\n",
       "      <td>0_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.0016880035, 0.014373779, 0.05230713, 0.000...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Swedish Neonatal Quality Register (SNQ)</td>\n",
       "      <td>34</td>\n",
       "      <td>6_1</td>\n",
       "      <td>6_1</td>\n",
       "      <td>[-0.045928955, 0.035369873, 0.01473999, 0.0049...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Persistent Pain Outcomes Collaboration (PPOC)</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[-0.053222656, 0.016342163, 0.062927246, 0.006...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>National Health Insurance claims data (NHI)</td>\n",
       "      <td>3</td>\n",
       "      <td>8_1</td>\n",
       "      <td>8_1</td>\n",
       "      <td>[-0.014968872, 0.0065956116, 0.048461914, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>8_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Danish Fracture Database (DFD)</td>\n",
       "      <td>8</td>\n",
       "      <td>0_1</td>\n",
       "      <td>0_1</td>\n",
       "      <td>[0.0064468384, 0.025680542, 0.022277832, -0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>National Health Insurance Research Database (N...</td>\n",
       "      <td>173</td>\n",
       "      <td>8_1</td>\n",
       "      <td>8_1</td>\n",
       "      <td>[-0.038085938, 0.0053596497, 0.02760315, 0.027...</td>\n",
       "      <td>1</td>\n",
       "      <td>8_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Society of Thoracic Surgeons/American College ...</td>\n",
       "      <td>92</td>\n",
       "      <td>9_1</td>\n",
       "      <td>9_1</td>\n",
       "      <td>[-0.017730713, 0.0022506714, 0.0009622574, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>9_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>REGistry of long-term AnTithrombotic TherApy (...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[-0.031280518, -0.016159058, 0.035369873, 0.00...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Swedish Cancer Register (SCR)</td>\n",
       "      <td>214</td>\n",
       "      <td>6_2</td>\n",
       "      <td>6_2</td>\n",
       "      <td>[-0.018249512, 0.006668091, 0.030090332, -0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>6_2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Scandinavian Donations and Transfusions Databa...</td>\n",
       "      <td>3</td>\n",
       "      <td>11_1</td>\n",
       "      <td>11_1</td>\n",
       "      <td>[-0.022155762, 0.023727417, 0.018615723, 0.004...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Swedish Patient Registry (SPR)</td>\n",
       "      <td>58</td>\n",
       "      <td>6_3</td>\n",
       "      <td>6_3</td>\n",
       "      <td>[-0.027908325, 0.016159058, 0.017745972, -0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>6_3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COnsortium of Rheumatology Researchers Of Nort...</td>\n",
       "      <td>55</td>\n",
       "      <td>12_1</td>\n",
       "      <td>12_1</td>\n",
       "      <td>[-0.04534912, 0.0030269623, 0.050842285, -0.00...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>National Database of Rheumatic Diseases by iR-...</td>\n",
       "      <td>2</td>\n",
       "      <td>13_1</td>\n",
       "      <td>13_1</td>\n",
       "      <td>[-0.015274048, 0.021240234, 0.04510498, 0.0124...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NCDR CathPCI Registry (NCDR CathPCI)</td>\n",
       "      <td>18</td>\n",
       "      <td>14_1</td>\n",
       "      <td>14_1</td>\n",
       "      <td>[-0.018966675, 0.006263733, 0.019378662, -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>14_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Osaka Cancer Registry (OCR)</td>\n",
       "      <td>104</td>\n",
       "      <td>15_1</td>\n",
       "      <td>15_1</td>\n",
       "      <td>[-0.0027751923, 0.0129852295, 0.04815674, -0.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>German Resuscitation Registry (GRR)</td>\n",
       "      <td>63</td>\n",
       "      <td>16_1</td>\n",
       "      <td>16_1</td>\n",
       "      <td>[-0.053497314, 0.00047898293, 0.022613525, -0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Surveillance Epidemiology and End Results Prog...</td>\n",
       "      <td>5406</td>\n",
       "      <td>6_4</td>\n",
       "      <td>6_4</td>\n",
       "      <td>[-0.031982422, 0.012542725, 0.03793335, 0.0097...</td>\n",
       "      <td>1</td>\n",
       "      <td>6_4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EVASTENT Registry (EVASTENT)</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>[-0.040496826, 0.026779175, 0.017578125, -0.00...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ReumaCoV-Brasil Registry (ReumaCoV-Brasil)</td>\n",
       "      <td>3</td>\n",
       "      <td>18_1</td>\n",
       "      <td>18_1</td>\n",
       "      <td>[-0.021392822, 0.0022735596, 0.045410156, -0.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Penn State Clinical Assessment and Rating Eval...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>[-0.033813477, 0.023330688, 0.008895874, 0.012...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Japanese Data Center for Hematopoietic Cell Tr...</td>\n",
       "      <td>4</td>\n",
       "      <td>20_1</td>\n",
       "      <td>20_1</td>\n",
       "      <td>[-0.0071983337, 0.027114868, 0.021438599, 0.01...</td>\n",
       "      <td>1</td>\n",
       "      <td>20_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>European Prospective Investigation into Cancer...</td>\n",
       "      <td>157</td>\n",
       "      <td>21_1</td>\n",
       "      <td>21_1</td>\n",
       "      <td>[-0.029449463, -0.0151901245, 0.04498291, 0.02...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Florida Cancer Registry (FCR)</td>\n",
       "      <td>28</td>\n",
       "      <td>0_1</td>\n",
       "      <td>0_1</td>\n",
       "      <td>[-0.018310547, 0.026489258, 0.027862549, -0.00...</td>\n",
       "      <td>1251</td>\n",
       "      <td>0_1_1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>German Fanconi Anemia Registry (GEFA)</td>\n",
       "      <td>2</td>\n",
       "      <td>0_1</td>\n",
       "      <td>0_1</td>\n",
       "      <td>[-0.019943237, 0.009162903, 0.04058838, 0.0052...</td>\n",
       "      <td>38</td>\n",
       "      <td>0_1_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NCDR ICD Registry (NCDR-ICD)</td>\n",
       "      <td>12</td>\n",
       "      <td>14_2</td>\n",
       "      <td>14_2</td>\n",
       "      <td>[-0.040039062, 0.016799927, -0.004257202, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>14_2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>UK Joint Theatre Trauma Registry (JTTR)</td>\n",
       "      <td>31</td>\n",
       "      <td>22_1</td>\n",
       "      <td>22_1</td>\n",
       "      <td>[-0.039093018, 0.026443481, 0.032714844, -0.00...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>United Network for Organ Sharing (UNOS)</td>\n",
       "      <td>455</td>\n",
       "      <td>23_1</td>\n",
       "      <td>23_1</td>\n",
       "      <td>[-0.022644043, 0.03765869, -0.0021457672, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>23_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>National Registry of Cardiovascular Interventi...</td>\n",
       "      <td>3</td>\n",
       "      <td>24_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.04385376, -0.001991272, 0.00017130375, -0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Enroll-HD (ENROLL-HD)</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.008041382, 0.0090789795, -0.0023937225, -0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>European Huntington's Disease Network Registry...</td>\n",
       "      <td>42</td>\n",
       "      <td>26_1</td>\n",
       "      <td>26_1</td>\n",
       "      <td>[-0.020401001, -0.0049972534, 0.0014572144, 0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Global Registry of Acute Coronary Events (GRACE)</td>\n",
       "      <td>652</td>\n",
       "      <td>27_1</td>\n",
       "      <td>27_1</td>\n",
       "      <td>[-0.036743164, 0.0034694672, 0.024398804, 0.00...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Canada Acute Coronary Syndrome risk score regi...</td>\n",
       "      <td>1</td>\n",
       "      <td>28_1</td>\n",
       "      <td>28_1</td>\n",
       "      <td>[-0.010528564, 0.010948181, 0.012374878, 0.004...</td>\n",
       "      <td>1</td>\n",
       "      <td>28_1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Swiss Clinical Quality Management Registry (SCQM)</td>\n",
       "      <td>9</td>\n",
       "      <td>6_5</td>\n",
       "      <td>6_5</td>\n",
       "      <td>[-0.026809692, 0.015670776, 0.007896423, -0.01...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>California Cancer Registry (CCR)</td>\n",
       "      <td>589</td>\n",
       "      <td>6_6</td>\n",
       "      <td>6_6</td>\n",
       "      <td>[-0.020858765, 0.004310608, 0.02796936, -0.004...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>St Thomas' Adult UK Twin Register (TATR)</td>\n",
       "      <td>1</td>\n",
       "      <td>29_1</td>\n",
       "      <td>29_1</td>\n",
       "      <td>[-0.032928467, 0.025848389, 0.0062828064, 0.00...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Brazilian Health Registry (BHR)</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>[-0.021743774, -0.0041999817, 0.030776978, -0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Population based Haematological Registry in th...</td>\n",
       "      <td>1</td>\n",
       "      <td>31_1</td>\n",
       "      <td>31_1</td>\n",
       "      <td>[-0.0140686035, 0.007888794, 0.04071045, 0.018...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Registry to Evaluate Early and Long-term Pulmo...</td>\n",
       "      <td>46</td>\n",
       "      <td>32_1</td>\n",
       "      <td>32_1</td>\n",
       "      <td>[-0.044677734, 0.009025574, 0.014587402, 0.002...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Extensively Drug-resistant Organism (XDRO) Reg...</td>\n",
       "      <td>1</td>\n",
       "      <td>33_1</td>\n",
       "      <td>33_1</td>\n",
       "      <td>[0.019943237, 0.0038318634, 0.011772156, -0.03...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Dutch Biologic Monitor (DBM)</td>\n",
       "      <td>4</td>\n",
       "      <td>0_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.016448975, 0.0073242188, 0.03213501, 0.011...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CORONOR (CORONOR)</td>\n",
       "      <td>2</td>\n",
       "      <td>0_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.028366089, -0.00579834, 0.032440186, -0.03...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>UK Barrett's Oesophagus Registry (UK BE Registry)</td>\n",
       "      <td>4</td>\n",
       "      <td>34_1</td>\n",
       "      <td>34_1</td>\n",
       "      <td>[-0.02722168, 0.011550903, 0.024246216, -0.041...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Resident Assessment Instrument-Home Care (RAI-HC)</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>[-0.05038452, 0.028533936, 0.020050049, 0.0478...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Danish Cancer Registry (CR)</td>\n",
       "      <td>774</td>\n",
       "      <td>6_7</td>\n",
       "      <td>6_7</td>\n",
       "      <td>[-0.024154663, 0.0211792, 0.042816162, 0.00136...</td>\n",
       "      <td>1</td>\n",
       "      <td>6_7_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            full_name  number_of_occurrences  \\\n",
       "0                        Spanish ABPM Registry (ABPM)                     12   \n",
       "1    Fasa Registry for Systolic Heart Failure (FARSH)                      1   \n",
       "2                          OnCovid Registry (OnCovid)                     12   \n",
       "3              New York State Cancer Registry (NYSCR)                     62   \n",
       "4              China Liver Transplant Registry (CLTR)                     39   \n",
       "5                               CMR-COVID (CMR-COVID)                      2   \n",
       "6                               SAR-COVID (SAR-COVID)                      3   \n",
       "7             Swedish Neonatal Quality Register (SNQ)                     34   \n",
       "8       Persistent Pain Outcomes Collaboration (PPOC)                      1   \n",
       "9         National Health Insurance claims data (NHI)                      3   \n",
       "10                     Danish Fracture Database (DFD)                      8   \n",
       "11  National Health Insurance Research Database (N...                    173   \n",
       "12  Society of Thoracic Surgeons/American College ...                     92   \n",
       "13  REGistry of long-term AnTithrombotic TherApy (...                      7   \n",
       "14                      Swedish Cancer Register (SCR)                    214   \n",
       "15  Scandinavian Donations and Transfusions Databa...                      3   \n",
       "16                     Swedish Patient Registry (SPR)                     58   \n",
       "17  COnsortium of Rheumatology Researchers Of Nort...                     55   \n",
       "18  National Database of Rheumatic Diseases by iR-...                      2   \n",
       "19               NCDR CathPCI Registry (NCDR CathPCI)                     18   \n",
       "20                        Osaka Cancer Registry (OCR)                    104   \n",
       "21                German Resuscitation Registry (GRR)                     63   \n",
       "22  Surveillance Epidemiology and End Results Prog...                   5406   \n",
       "23                       EVASTENT Registry (EVASTENT)                      1   \n",
       "24         ReumaCoV-Brasil Registry (ReumaCoV-Brasil)                      3   \n",
       "25  Penn State Clinical Assessment and Rating Eval...                      1   \n",
       "26  Japanese Data Center for Hematopoietic Cell Tr...                      4   \n",
       "27  European Prospective Investigation into Cancer...                    157   \n",
       "28                      Florida Cancer Registry (FCR)                     28   \n",
       "29              German Fanconi Anemia Registry (GEFA)                      2   \n",
       "30                       NCDR ICD Registry (NCDR-ICD)                     12   \n",
       "31            UK Joint Theatre Trauma Registry (JTTR)                     31   \n",
       "32            United Network for Organ Sharing (UNOS)                    455   \n",
       "33  National Registry of Cardiovascular Interventi...                      3   \n",
       "34                              Enroll-HD (ENROLL-HD)                     36   \n",
       "35  European Huntington's Disease Network Registry...                     42   \n",
       "36   Global Registry of Acute Coronary Events (GRACE)                    652   \n",
       "37  Canada Acute Coronary Syndrome risk score regi...                      1   \n",
       "38  Swiss Clinical Quality Management Registry (SCQM)                      9   \n",
       "39                   California Cancer Registry (CCR)                    589   \n",
       "40           St Thomas' Adult UK Twin Register (TATR)                      1   \n",
       "41                    Brazilian Health Registry (BHR)                      1   \n",
       "42  Population based Haematological Registry in th...                      1   \n",
       "43  Registry to Evaluate Early and Long-term Pulmo...                     46   \n",
       "44  Extensively Drug-resistant Organism (XDRO) Reg...                      1   \n",
       "45                       Dutch Biologic Monitor (DBM)                      4   \n",
       "46                                  CORONOR (CORONOR)                      2   \n",
       "47  UK Barrett's Oesophagus Registry (UK BE Registry)                      4   \n",
       "48  Resident Assessment Instrument-Home Care (RAI-HC)                      3   \n",
       "49                        Danish Cancer Registry (CR)                    774   \n",
       "\n",
       "   cluster_0 corrected_cluster  \\\n",
       "0        1_1               1_1   \n",
       "1          2                 2   \n",
       "2          3                 3   \n",
       "3          4                 4   \n",
       "4        5_1               5_1   \n",
       "5        0_0               NaN   \n",
       "6        0_0               NaN   \n",
       "7        6_1               6_1   \n",
       "8          7                 7   \n",
       "9        8_1               8_1   \n",
       "10       0_1               0_1   \n",
       "11       8_1               8_1   \n",
       "12       9_1               9_1   \n",
       "13        10                10   \n",
       "14       6_2               6_2   \n",
       "15      11_1              11_1   \n",
       "16       6_3               6_3   \n",
       "17      12_1              12_1   \n",
       "18      13_1              13_1   \n",
       "19      14_1              14_1   \n",
       "20      15_1              15_1   \n",
       "21      16_1              16_1   \n",
       "22       6_4               6_4   \n",
       "23        17                17   \n",
       "24      18_1              18_1   \n",
       "25        19                19   \n",
       "26      20_1              20_1   \n",
       "27      21_1              21_1   \n",
       "28       0_1               0_1   \n",
       "29       0_1               0_1   \n",
       "30      14_2              14_2   \n",
       "31      22_1              22_1   \n",
       "32      23_1              23_1   \n",
       "33      24_0               NaN   \n",
       "34        25                25   \n",
       "35      26_1              26_1   \n",
       "36      27_1              27_1   \n",
       "37      28_1              28_1   \n",
       "38       6_5               6_5   \n",
       "39       6_6               6_6   \n",
       "40      29_1              29_1   \n",
       "41        30                30   \n",
       "42      31_1              31_1   \n",
       "43      32_1              32_1   \n",
       "44      33_1              33_1   \n",
       "45       0_0               NaN   \n",
       "46       0_0               NaN   \n",
       "47      34_1              34_1   \n",
       "48        35                35   \n",
       "49       6_7               6_7   \n",
       "\n",
       "                                  full_name_embedding subcluster cluster_1  \n",
       "0   [-0.035308838, -0.005203247, 0.026031494, -0.0...       None      None  \n",
       "1   [-0.03074646, 0.028259277, 0.022598267, -0.019...       None      None  \n",
       "2   [-0.019241333, -0.008605957, 0.04559326, -0.01...       None      None  \n",
       "3   [-0.0053710938, 0.018249512, 0.044647217, -0.0...       None      None  \n",
       "4   [-0.03540039, 0.009819031, -0.0044784546, -0.0...       None      None  \n",
       "5   [-0.034179688, 0.0039596558, 0.05001831, -0.02...       None      None  \n",
       "6   [-0.0016880035, 0.014373779, 0.05230713, 0.000...       None      None  \n",
       "7   [-0.045928955, 0.035369873, 0.01473999, 0.0049...       None      None  \n",
       "8   [-0.053222656, 0.016342163, 0.062927246, 0.006...       None      None  \n",
       "9   [-0.014968872, 0.0065956116, 0.048461914, -0.0...          1     8_1_1  \n",
       "10  [0.0064468384, 0.025680542, 0.022277832, -0.00...          0      None  \n",
       "11  [-0.038085938, 0.0053596497, 0.02760315, 0.027...          1     8_1_1  \n",
       "12  [-0.017730713, 0.0022506714, 0.0009622574, 0.0...          1     9_1_1  \n",
       "13  [-0.031280518, -0.016159058, 0.035369873, 0.00...       None      None  \n",
       "14  [-0.018249512, 0.006668091, 0.030090332, -0.00...          1     6_2_1  \n",
       "15  [-0.022155762, 0.023727417, 0.018615723, 0.004...       None      None  \n",
       "16  [-0.027908325, 0.016159058, 0.017745972, -0.00...          1     6_3_1  \n",
       "17  [-0.04534912, 0.0030269623, 0.050842285, -0.00...       None      None  \n",
       "18  [-0.015274048, 0.021240234, 0.04510498, 0.0124...       None      None  \n",
       "19  [-0.018966675, 0.006263733, 0.019378662, -0.02...          1    14_1_1  \n",
       "20  [-0.0027751923, 0.0129852295, 0.04815674, -0.0...       None      None  \n",
       "21  [-0.053497314, 0.00047898293, 0.022613525, -0....       None      None  \n",
       "22  [-0.031982422, 0.012542725, 0.03793335, 0.0097...          1     6_4_1  \n",
       "23  [-0.040496826, 0.026779175, 0.017578125, -0.00...       None      None  \n",
       "24  [-0.021392822, 0.0022735596, 0.045410156, -0.0...       None      None  \n",
       "25  [-0.033813477, 0.023330688, 0.008895874, 0.012...       None      None  \n",
       "26  [-0.0071983337, 0.027114868, 0.021438599, 0.01...          1    20_1_1  \n",
       "27  [-0.029449463, -0.0151901245, 0.04498291, 0.02...       None      None  \n",
       "28  [-0.018310547, 0.026489258, 0.027862549, -0.00...       1251  0_1_1251  \n",
       "29  [-0.019943237, 0.009162903, 0.04058838, 0.0052...         38    0_1_38  \n",
       "30  [-0.040039062, 0.016799927, -0.004257202, -0.0...          1    14_2_1  \n",
       "31  [-0.039093018, 0.026443481, 0.032714844, -0.00...       None      None  \n",
       "32  [-0.022644043, 0.03765869, -0.0021457672, -0.0...          1    23_1_1  \n",
       "33  [-0.04385376, -0.001991272, 0.00017130375, -0....       None      None  \n",
       "34  [-0.008041382, 0.0090789795, -0.0023937225, -0...       None      None  \n",
       "35  [-0.020401001, -0.0049972534, 0.0014572144, 0....       None      None  \n",
       "36  [-0.036743164, 0.0034694672, 0.024398804, 0.00...       None      None  \n",
       "37  [-0.010528564, 0.010948181, 0.012374878, 0.004...          1    28_1_1  \n",
       "38  [-0.026809692, 0.015670776, 0.007896423, -0.01...       None      None  \n",
       "39  [-0.020858765, 0.004310608, 0.02796936, -0.004...       None      None  \n",
       "40  [-0.032928467, 0.025848389, 0.0062828064, 0.00...       None      None  \n",
       "41  [-0.021743774, -0.0041999817, 0.030776978, -0....       None      None  \n",
       "42  [-0.0140686035, 0.007888794, 0.04071045, 0.018...       None      None  \n",
       "43  [-0.044677734, 0.009025574, 0.014587402, 0.002...       None      None  \n",
       "44  [0.019943237, 0.0038318634, 0.011772156, -0.03...       None      None  \n",
       "45  [-0.016448975, 0.0073242188, 0.03213501, 0.011...       None      None  \n",
       "46  [-0.028366089, -0.00579834, 0.032440186, -0.03...       None      None  \n",
       "47  [-0.02722168, 0.011550903, 0.024246216, -0.041...       None      None  \n",
       "48  [-0.05038452, 0.028533936, 0.020050049, 0.0478...       None      None  \n",
       "49  [-0.024154663, 0.0211792, 0.042816162, 0.00136...          1     6_7_1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the best configuration datframe\n",
    "print(\"Best configuration DataFrame:\")\n",
    "display(clusters_best_config_df.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc368690",
   "metadata": {},
   "source": [
    "## Grid search complete\n",
    "- All results are saved in `grid_search_results.xlsx`.\n",
    "- The best configuration is saved in `best_config.json`.\n",
    "- You can now use the best configuration for further clustering and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f06eba",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P05_refine_dedup_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
